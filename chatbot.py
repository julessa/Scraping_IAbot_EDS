import os
import json
import time  # Pour time.sleep
import requests
import streamlit as st
from streamlit_lottie import st_lottie
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from langchain.chains import RetrievalQA
from langchain.vectorstores import Chroma
from datetime import datetime
import plotly.express as px
from sklearn.decomposition import PCA
import numpy as np
import pandas as pd
import re

# D√©sactivez le mode multi‚Äëtenant d√®s le d√©but
os.environ["CHROMADB_DISABLE_MULTITENANT"] = "true"

# Configuration de la page
st.set_page_config(page_title="Chatbot Historique ‚öîÔ∏è", page_icon="‚öîÔ∏è", layout="centered")

# Styles CSS personnalis√©s
st.markdown(
    """
    <style>
        body {
            background-color: #f3f4f6;
            font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
        }
        .stButton>button {
            color: white;
            background-color: #4CAF50;
            border-radius: 10px;
            font-size: 18px;
            padding: 10px 20px;
            border: none;
        }
        .stTextInput>div>div>input {
            background-color: #ffffff;
            color: black;
            font-size: 16px;
            padding: 8px;
        }
        .container {
            max-width: 700px;
            margin: auto;
            padding: 20px;
            background: white;
            border-radius: 10px;
            box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.1);
            text-align: center;
        }
        .header {
            text-align: center;
            padding: 20px;
        }
        .lottie-container {
            display: flex;
            justify-content: center;
            align-items: center;
        }
    </style>
    """,
    unsafe_allow_html=True
)

# Chargement de l'animation depuis le fichier JSON
with open("soldiers_animation.json", "r") as f:
    lottie_soldiers = json.load(f)

# V√©rification de la cl√© API OpenAI
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    st.error("üö® Cl√© API OpenAI non trouv√©e.")
    st.stop()

# Chargement des donn√©es JSON contenant les √©v√©nements historiques
with open("combined_data.json", "r", encoding="utf-8") as f:
    data = json.load(f)

# Filtrer les documents entre 1914 et 1945
def filter_documents_by_date(documents, start_year=1914, end_year=1945):
    """
    Filtrer les documents pour inclure uniquement ceux entre 1914 et 1945.
    Ajoute une gestion d'erreurs pour les dates mal format√©es et les dates sous format texte.
    """
    filtered_docs = []
    
    for doc in documents:
        date_str = doc['date']  # Exemple : "18 d√©cembre 1917"
        
        # Expression r√©guli√®re pour extraire l'ann√©e √† partir de la cha√Æne de texte
        match = re.search(r'\b(\d{4})\b', date_str)  # Recherche un nombre √† 4 chiffres (ann√©e)
        
        if match:
            year = int(match.group(1))  # Extraire l'ann√©e du match trouv√©
            if start_year <= year <= end_year:
                filtered_docs.append(doc)
        else:
            # Si aucune ann√©e n'est trouv√©e, on peut l'ignorer ou g√©rer l'erreur
            print(f"Date mal format√©e ou sans ann√©e : {date_str}")
    
    return filtered_docs

# Filtrer les documents par p√©riode (1914-1945)
filtered_data = filter_documents_by_date(data)

# Filtrer les doublons et transformer les entr√©es en documents LangChain
docs = []
for entry in filtered_data:
    if "duplicate" in entry and not entry["duplicate"]:
        text = f"{entry['date']} : {entry['event']}"
        docs.append(Document(page_content=text))

# D√©coupage des documents en morceaux
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
split_docs = text_splitter.split_documents(docs)

# Initialisation (ou chargement) de la base vectorielle Chroma
persist_directory = "chroma_db"
embedding = OpenAIEmbeddings(openai_api_key=openai_api_key)
if os.path.exists(persist_directory) and os.listdir(persist_directory):
    vector_store = Chroma(
        persist_directory=persist_directory,
        embedding_function=embedding
    )
else:
    vector_store = Chroma.from_documents(
        documents=split_docs,
        embedding=embedding,
        persist_directory=persist_directory
    )
    vector_store.persist()

# Cr√©ation du retriever pour interroger la base de donn√©es
retriever = vector_store.as_retriever()

# Configuration du mod√®le OpenAI via LangChain
llm = ChatOpenAI(
    model="gpt-3.5-turbo",
    openai_api_key=openai_api_key,
    temperature=0.0
)

# Construction de la cha√Æne de questions-r√©ponses
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
)

# --- BOUTON D'ACTUALISATION DANS L'OVERLAY GAUCHE ---
def my_rerun():
    if hasattr(st, "experimental_rerun"):
        st.experimental_rerun()
    else:
        st.warning("La fonction de rafra√Æchissement n'est pas support√©e dans votre version de Streamlit. Veuillez mettre √† jour Streamlit (pip install --upgrade streamlit).")

st.sidebar.button("Actualiser l'historique", on_click=my_rerun)

# --- MENU LAT√âRAL ---
st.sidebar.header("Instructions")
st.sidebar.info(
    "Posez vos questions sur l'histoire de France via le formulaire principal. "
    "L'historique des interactions est affich√© ci-dessous."
)

with st.sidebar.expander("Historique des interactions r√©cents"):
    with st.spinner("Chargement de l'historique..."):
        results = vector_store.similarity_search("R√©ponse", k=5)
        if results:
            for doc in results:
                st.markdown(doc.page_content)
                st.markdown("---")
        else:
            st.info("Aucune interaction trouv√©e.")

st.sidebar.markdown("### √Ä propos")
st.sidebar.info(
    "Ce chatbot utilise LangChain et l'API OpenAI pour r√©pondre √† vos questions sur l'histoire de France. "
    "Les interactions sont sauvegard√©es et affich√©es dans l'historique."
)

# --- ZONE PRINCIPALE ---
with st.container():
    st.markdown('<div class="header"><h1>‚öîÔ∏è Chatbot Historique ‚öîÔ∏è</h1></div>', unsafe_allow_html=True)
    st_lottie(lottie_soldiers, speed=1, width=400, height=300, key="soldiers")

# Fonction pour interroger le chatbot et enregistrer l'historique
def chat_with_bot(query):
    # Filtrer la question par date (permet d'√©viter les questions hors p√©riode)
    date_match = re.search(r'\b(\d{1,2})\s([a-zA-Z√©√†√ª]+)\s(\d{4})\b', query)  # D√©tecter les dates dans le format "18 juin 1917"
    if date_match:
        year = int(date_match.group(3))
        if year < 1914 or year > 1945:
            return "D√©sol√©, je ne peux r√©pondre qu'aux √©v√©nements entre 1914 et 1945."

    response = qa_chain.run(query)
    time.sleep(1)  # Pause d'1 seconde pour limiter le risque de blocage par l'API OpenAI

    # Ajout d'un timestamp pour chaque interaction
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    history_entry = f"**[{timestamp}] Question:** {query}\n\n**R√©ponse:** {response}"
    history_doc = Document(page_content=history_entry)

    # Ajout de l'entr√©e d'historique √† Chroma et sauvegarde
    vector_store.add_documents([history_doc])
    vector_store.persist()

    return response

# Formulaire pour saisir la question avec bouton centr√©
with st.form(key="chat_form", clear_on_submit=True):
    query = st.text_input("Posez votre question sur l'histoire de France :", "")
    col1, col2, col3 = st.columns([1, 1, 1])
    submit_button = col2.form_submit_button("Envoyer")

if submit_button:
    if query:
        with st.spinner("Recherche..."):
            response = chat_with_bot(query)
        st.markdown("### R√©ponse :")
        st.write(response)
    else:
        st.warning("Veuillez entrer une question.")

# Ajout d'une case √† cocher "J'accepte les cookies et conditions d'utilisation"
st.checkbox("J'accepte les cookies et conditions d'utilisation")

# Option de t√©l√©chargement de l'historique complet dans la sidebar
with st.sidebar.expander("T√©l√©charger l'historique complet"):
    with st.spinner("Pr√©paration du fichier..."):
        results_all = vector_store.similarity_search("R√©ponse", k=100)
        history_text = "\n\n".join([doc.page_content for doc in results_all])
    st.download_button("T√©l√©charger l'historique", history_text, "historique.txt", "text/plain")
